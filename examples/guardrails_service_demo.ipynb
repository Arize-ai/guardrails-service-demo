{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardrails Service Demo\n",
    "\n",
    "This notebook demonstrates how to use the Guardrails Service for anomaly detection in text requests. The service uses vector embeddings to compare incoming requests against a baseline dataset and detect anomalies.\n",
    "\n",
    "We'll use a realistic dataset of 100 pharmacy customer questions to demonstrate how the service works in a real-world scenario.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. Started the Guardrails Service: `uv run uvicorn guardrails_service.main:app --reload`\n",
    "2. Installed required dependencies: `uv sync --examples`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "from typing import Optional\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "directory = os.path.abspath(\".\") + \"/examples\"\n",
    "service_process: Optional[subprocess.Popen] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Guardrails Service\n",
    "\n",
    "This will start the service in the background so we can interact with it through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Service is already running\n"
     ]
    }
   ],
   "source": [
    "def start_service():\n",
    "    \"\"\"Start the guardrails service in the background\"\"\"\n",
    "    global service_process\n",
    "    try:\n",
    "        # Check if service is already running\n",
    "        response = httpx.get(f\"{BASE_URL}/health\", timeout=2)\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Service is already running\")\n",
    "            return\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"üöÄ Starting Guardrails Service...\")\n",
    "    \n",
    "    # Change to the project directory\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "    # Start the service\n",
    "    service_process = subprocess.Popen(\n",
    "        [\"uv\", \"run\", \"uvicorn\", \"guardrails_service.server:app\", \"--port\", \"8000\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Wait for service to start\n",
    "    for i in range(30):  # Wait up to 30 seconds\n",
    "        try:\n",
    "            response = httpx.get(f\"{BASE_URL}/health\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úÖ Service started successfully!\")\n",
    "                return\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "    \n",
    "    print(\"‚ùå Failed to start service\")\n",
    "\n",
    "def stop_service():\n",
    "    \"\"\"Stop the guardrails service\"\"\"\n",
    "    global service_process\n",
    "    if service_process:\n",
    "        print(\"üõë Stopping Guardrails Service...\")\n",
    "        service_process.terminate()\n",
    "        service_process.wait()\n",
    "        service_process = None\n",
    "        print(\"‚úÖ Service stopped\")\n",
    "\n",
    "# Start the service\n",
    "start_service()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's create some helper functions to interact with the API more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def health_check():\n    \"\"\"Check if the service is healthy\"\"\"\n    response = httpx.get(f\"{BASE_URL}/health\")\n    return response.json()\n\ndef upload_baseline(requests_data):\n    \"\"\"Upload a baseline dataset\"\"\"\n    payload = {\n        \"requests\": [\n            {\n                \"text\": req[\"text\"],\n                \"timestamp\": req[\"timestamp\"]\n            }\n            for req in requests_data\n        ]\n    }\n    response = httpx.post(f\"{BASE_URL}/anomaly/baseline/upload\", json=payload)\n    return response.json()\n\ndef add_to_baseline(text, timestamp=None):\n    \"\"\"Add a single request to the baseline\"\"\"\n    if timestamp is None:\n        timestamp = datetime.now().isoformat()\n    \n    payload = {\n        \"text\": text,\n        \"timestamp\": timestamp\n    }\n    response = httpx.post(f\"{BASE_URL}/anomaly/baseline/add\", json=payload)\n    return response.json()\n\ndef detect_anomaly(text, threshold=None, compare_to=None, timestamp=None):\n    \"\"\"Run anomaly detection on a text request\"\"\"\n    payload = {\n        \"text\": text\n    }\n    \n    if timestamp:\n        payload[\"timestamp\"] = timestamp\n    if threshold is not None:\n        payload[\"threshold\"] = threshold\n    if compare_to is not None:\n        payload[\"compare_to\"] = compare_to\n    \n    response = httpx.post(f\"{BASE_URL}/anomaly/detect\", json=payload)\n    return response.json()\n\ndef get_baseline_stats():\n    \"\"\"Get baseline dataset statistics\"\"\"\n    response = httpx.get(f\"{BASE_URL}/anomaly/baseline/stats\")\n    return response.json()\n\ndef clear_baseline():\n    \"\"\"Clear all baseline data\"\"\"\n    payload = {}\n    response = httpx.post(f\"{BASE_URL}/anomaly/baseline/clear\", json=payload)\n    return response.json()\n\n# Malicious Detection Helper Functions\n\ndef upload_malicious_baseline(requests_data):\n    \"\"\"Upload a malicious baseline dataset\"\"\"\n    payload = {\n        \"requests\": [\n            {\n                \"text\": req[\"text\"],\n                \"timestamp\": req[\"timestamp\"]\n            }\n            for req in requests_data\n        ]\n    }\n    response = httpx.post(f\"{BASE_URL}/malicious/baseline/upload\", json=payload)\n    return response.json()\n\ndef add_to_malicious_baseline(text, timestamp=None):\n    \"\"\"Add a single request to the malicious baseline\"\"\"\n    if timestamp is None:\n        timestamp = datetime.now().isoformat()\n    \n    payload = {\n        \"text\": text,\n        \"timestamp\": timestamp\n    }\n    response = httpx.post(f\"{BASE_URL}/malicious/baseline/add\", json=payload)\n    return response.json()\n\ndef detect_malicious(text, threshold=None, compare_to=None, timestamp=None):\n    \"\"\"Run malicious detection on a text request\"\"\"\n    payload = {\n        \"text\": text\n    }\n    \n    if timestamp:\n        payload[\"timestamp\"] = timestamp\n    if threshold is not None:\n        payload[\"threshold\"] = threshold\n    if compare_to is not None:\n        payload[\"compare_to\"] = compare_to\n    \n    response = httpx.post(f\"{BASE_URL}/malicious/detect\", json=payload)\n    return response.json()\n\ndef get_malicious_baseline_stats():\n    \"\"\"Get malicious baseline dataset statistics\"\"\"\n    response = httpx.get(f\"{BASE_URL}/malicious/baseline/stats\")\n    return response.json()\n\ndef clear_malicious_baseline():\n    \"\"\"Clear all malicious baseline data\"\"\"\n    payload = {}\n    response = httpx.post(f\"{BASE_URL}/malicious/baseline/clear\", json=payload)\n    return response.json()\n\ndef pretty_print_result(result, title=\"\"):\n    \"\"\"Pretty print anomaly detection results\"\"\"\n    if title:\n        print(f\"\\n=== {title} ===\")\n    \n    if \"result\" in result:\n        r = result[\"result\"]\n        \n        # Handle both anomaly and malicious results\n        if \"is_anomaly\" in r:\n            status = \"üö® ANOMALY\" if r[\"is_anomaly\"] else \"‚úÖ NORMAL\"\n            reasons_key = \"anomaly_reasons\"\n        elif \"is_malicious\" in r:\n            status = \"üö® MALICIOUS\" if r[\"is_malicious\"] else \"‚úÖ BENIGN\"\n            reasons_key = \"malicious_reasons\"\n        else:\n            status = \"‚ùì UNKNOWN\"\n            reasons_key = \"reasons\"\n            \n        print(f\"{status} - Confidence: {r['confidence_score']:.3f} - Risk: {r['risk_level']}\")\n        print(f\"Similar records: {r['similar_records_count']}\")\n        \n        if reasons_key in r and r[reasons_key]:\n            print(\"Reasons:\")\n            for reason in r[reasons_key]:\n                print(f\"  - {reason}\")\n        \n        if \"baseline_stats\" in result and result[\"baseline_stats\"]:\n            stats = result[\"baseline_stats\"]\n            if \"threshold\" in stats:\n                print(f\"Threshold used: {stats['threshold']}\")\n            if \"detection_distance\" in stats:\n                print(f\"Detection distance ({stats.get('detection_metric', 'unknown')}): {stats['detection_distance']:.3f}\")\n    else:\n        print(json.dumps(result, indent=2))\n\n# Test the connection\nprint(\"Testing connection...\")\nprint(health_check())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clear Any Existing Baseline Data\n",
    "\n",
    "Let's start fresh by clearing any existing baseline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing baseline data...\n",
      "‚úÖ All baseline data cleared successfully\n",
      "Records removed: 0\n",
      "\n",
      "Baseline stats: {'total_records': 0, 'collection_name': 'traffic_baseline'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Clearing existing baseline data...\")\n",
    "result = clear_baseline()\n",
    "print(f\"‚úÖ {result['message']}\")\n",
    "print(f\"Records removed: {result['records_removed']}\")\n",
    "\n",
    "# Check baseline stats\n",
    "stats = get_baseline_stats()\n",
    "print(f\"\\nBaseline stats: {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Pharmacy Baseline Dataset\n",
    "\n",
    "We'll load a realistic dataset of 100 pharmacy customer questions from a JSON file. This represents normal pharmacy interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pharmacy baseline dataset from JSON file...\n",
      "Loaded 124 pharmacy questions\n",
      "\n",
      "Sample questions:\n",
      "  1. What time do you close today?\n",
      "  2. I need to refill my blood pressure medication, metoprolol 50mg\n",
      "  3. Do you have the flu vaccine available?\n",
      "  4. Can I pick up my prescription for amoxicillin today?\n",
      "  5. What are your hours on Sunday?\n",
      "\n",
      "Uploading baseline dataset to service...\n",
      "‚úÖ Baseline dataset uploaded successfully\n",
      "Records added: 124\n",
      "\n",
      "Updated baseline stats: {'total_records': 124, 'collection_name': 'traffic_baseline'}\n"
     ]
    }
   ],
   "source": [
    "# Load pharmacy baseline data from JSON file\n",
    "print(\"Loading pharmacy baseline dataset from JSON file...\")\n",
    "\n",
    "# Load the data from our JSON file\n",
    "with open(os.path.join(directory, \"data/baseline.json\"), \"r\") as f:\n",
    "    baseline_data = json.load(f)\n",
    "\n",
    "baseline_requests = baseline_data[\"requests\"]\n",
    "\n",
    "print(f\"Loaded {len(baseline_requests)} pharmacy questions\")\n",
    "print(\"\\nSample questions:\")\n",
    "for i, req in enumerate(baseline_requests[:5]):\n",
    "    print(f\"  {i+1}. {req['text']}\")\n",
    "\n",
    "print(\"\\nUploading baseline dataset to service...\")\n",
    "result = upload_baseline(baseline_requests)\n",
    "print(f\"‚úÖ {result['message']}\")\n",
    "print(f\"Records added: {result['records_added']}\")\n",
    "\n",
    "# Check baseline stats\n",
    "stats = get_baseline_stats()\n",
    "print(f\"\\nUpdated baseline stats: {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Anomaly Detection - Normal Pharmacy Questions\n",
    "\n",
    "Let's test some normal pharmacy questions that should be similar to our baseline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing normal pharmacy questions (should NOT be flagged as anomalies):\n",
      "======================================================================\n",
      "\n",
      "=== Question: I need to refill my blood pressure medication ===\n",
      "‚úÖ NORMAL - Confidence: 0.252 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.252\n",
      "\n",
      "=== Question: What are your pharmacy hours today? ===\n",
      "‚úÖ NORMAL - Confidence: 0.397 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.397\n",
      "\n",
      "=== Question: Can I pick up my prescription for my child? ===\n",
      "‚úÖ NORMAL - Confidence: 0.398 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.398\n",
      "\n",
      "=== Question: Do you accept my Medicare insurance? ===\n",
      "‚úÖ NORMAL - Confidence: 0.527 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.527\n",
      "\n",
      "=== Question: I need help understanding my medication dosage ===\n",
      "‚úÖ NORMAL - Confidence: 0.434 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.434\n",
      "\n",
      "=== Question: Can I get a flu shot here? ===\n",
      "‚úÖ NORMAL - Confidence: 0.607 - Risk: medium\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.607\n"
     ]
    }
   ],
   "source": [
    "# Test normal pharmacy questions (should not be flagged as anomalies)\n",
    "normal_pharmacy_questions = [\n",
    "    \"I need to refill my blood pressure medication\",\n",
    "    \"What are your pharmacy hours today?\",\n",
    "    \"Can I pick up my prescription for my child?\",\n",
    "    \"Do you accept my Medicare insurance?\",\n",
    "    \"I need help understanding my medication dosage\",\n",
    "    \"Can I get a flu shot here?\"\n",
    "]\n",
    "\n",
    "print(\"Testing normal pharmacy questions (should NOT be flagged as anomalies):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for question in normal_pharmacy_questions:\n",
    "    result = detect_anomaly(question)\n",
    "    pretty_print_result(result, f\"Question: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test Anomaly Detection - Suspicious/Inappropriate Requests\n",
    "\n",
    "Now let's test some suspicious or inappropriate requests that should be flagged as anomalies in a pharmacy context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing suspicious/inappropriate requests (should be flagged as anomalies):\n",
      "======================================================================\n",
      "\n",
      "=== Request: Can I buy oxycodone without a prescription? ===\n",
      "‚úÖ NORMAL - Confidence: 0.475 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.475\n",
      "\n",
      "=== Request: I want to purchase large quantities of pseudoephedrine for my lab ===\n",
      "‚úÖ NORMAL - Confidence: 0.544 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.544\n",
      "\n",
      "=== Request: How can I forge a prescription from my doctor? ===\n",
      "‚úÖ NORMAL - Confidence: 0.380 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.380\n",
      "\n",
      "=== Request: Can you sell me controlled substances under the table? ===\n",
      "‚úÖ NORMAL - Confidence: 0.591 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.591\n",
      "\n",
      "=== Request: I need access to your computer system to check my records ===\n",
      "‚úÖ NORMAL - Confidence: 0.650 - Risk: medium\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.650\n",
      "\n",
      "=== Request: '; DROP TABLE prescriptions; -- ===\n",
      "‚úÖ NORMAL - Confidence: 0.518 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.518\n",
      "\n",
      "=== Request: <script>alert('pharmacy hack')</script> ===\n",
      "‚úÖ NORMAL - Confidence: 0.581 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.581\n",
      "\n",
      "=== Request: ../../etc/passwd ===\n",
      "üö® ANOMALY - Confidence: 0.867 - Risk: high\n",
      "Similar records: 10\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.867\n",
      "\n",
      "=== Request: What's the pharmacist's home address? ===\n",
      "‚úÖ NORMAL - Confidence: 0.503 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.503\n",
      "\n",
      "=== Request: Can I get free drugs if I threaten you? ===\n",
      "‚úÖ NORMAL - Confidence: 0.625 - Risk: medium\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.625\n"
     ]
    }
   ],
   "source": [
    "# Test suspicious/inappropriate requests (should be flagged as anomalies)\n",
    "suspicious_requests = [\n",
    "    \"Can I buy oxycodone without a prescription?\",\n",
    "    \"I want to purchase large quantities of pseudoephedrine for my lab\",\n",
    "    \"How can I forge a prescription from my doctor?\",\n",
    "    \"Can you sell me controlled substances under the table?\",\n",
    "    \"I need access to your computer system to check my records\",\n",
    "    \"'; DROP TABLE prescriptions; --\",\n",
    "    \"<script>alert('pharmacy hack')</script>\",\n",
    "    \"../../etc/passwd\",\n",
    "    \"What's the pharmacist's home address?\",\n",
    "    \"Can I get free drugs if I threaten you?\"\n",
    "]\n",
    "\n",
    "print(\"Testing suspicious/inappropriate requests (should be flagged as anomalies):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for request in suspicious_requests:\n",
    "    result = detect_anomaly(request)\n",
    "    pretty_print_result(result, f\"Request: {request}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test Different Threshold Values\n",
    "\n",
    "Let's experiment with different threshold values to see how they affect anomaly detection sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing request 'I'm in a lot of pain, can you help me get some painkillers?' with different thresholds:\n",
      "======================================================================\n",
      "\n",
      "=== Threshold: 0.3 ===\n",
      "üö® ANOMALY - Confidence: 1.000 - Risk: high\n",
      "Similar records: 0\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n",
      "\n",
      "=== Threshold: 0.5 ===\n",
      "üö® ANOMALY - Confidence: 1.000 - Risk: high\n",
      "Similar records: 0\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n",
      "\n",
      "=== Threshold: 0.7 ===\n",
      "üö® ANOMALY - Confidence: 1.000 - Risk: high\n",
      "Similar records: 0\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n",
      "\n",
      "=== Threshold: 0.9 ===\n",
      "üö® ANOMALY - Confidence: 1.000 - Risk: high\n",
      "Similar records: 0\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n",
      "\n",
      "üìä Threshold Sensitivity Summary:\n",
      " threshold  is_anomaly  confidence_score risk_level\n",
      "       0.3        True               1.0       high\n",
      "       0.5        True               1.0       high\n",
      "       0.7        True               1.0       high\n",
      "       0.9        True               1.0       high\n"
     ]
    }
   ],
   "source": [
    "# Test the same request with different thresholds\n",
    "test_request = \"I'm in a lot of pain, can you help me get some painkillers?\"\n",
    "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "print(f\"Testing request '{test_request}' with different thresholds:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    result = detect_anomaly(test_request, threshold=threshold)\n",
    "    pretty_print_result(result, f\"Threshold: {threshold}\")\n",
    "    \n",
    "    # Store for summary\n",
    "    results_summary.append({\n",
    "        \"threshold\": threshold,\n",
    "        \"is_anomaly\": result[\"result\"][\"is_anomaly\"],\n",
    "        \"confidence_score\": result[\"result\"][\"confidence_score\"],\n",
    "        \"risk_level\": result[\"result\"][\"risk_level\"]\n",
    "    })\n",
    "\n",
    "# Create a summary table\n",
    "print(\"\\nüìä Threshold Sensitivity Summary:\")\n",
    "df = pd.DataFrame(results_summary)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Different Compare_To Values\n",
    "\n",
    "Let's test how changing the number of similar vectors to compare affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing request 'Can I get information about drug interactions with my supplements?' with different compare_to values:\n",
      "======================================================================\n",
      "\n",
      "=== Compare to: 3 vectors ===\n",
      "‚úÖ NORMAL - Confidence: 0.280 - Risk: low\n",
      "Similar records: 3\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.280\n",
      "\n",
      "=== Compare to: 5 vectors ===\n",
      "‚úÖ NORMAL - Confidence: 0.297 - Risk: low\n",
      "Similar records: 5\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.297\n",
      "\n",
      "=== Compare to: 10 vectors ===\n",
      "‚úÖ NORMAL - Confidence: 0.510 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.510\n",
      "\n",
      "=== Compare to: 15 vectors ===\n",
      "‚úÖ NORMAL - Confidence: 0.526 - Risk: low\n",
      "Similar records: 15\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.526\n",
      "\n",
      "üìä Compare_To Sensitivity Summary:\n",
      " compare_to  is_anomaly  confidence_score  similar_records_count\n",
      "          3       False          0.279543                      3\n",
      "          5       False          0.296986                      5\n",
      "         10       False          0.510487                     10\n",
      "         15       False          0.526456                     15\n"
     ]
    }
   ],
   "source": [
    "# Test the same request with different compare_to values\n",
    "test_request = \"Can I get information about drug interactions with my supplements?\"\n",
    "compare_to_values = [3, 5, 10, 15]\n",
    "\n",
    "print(f\"Testing request '{test_request}' with different compare_to values:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for compare_to in compare_to_values:\n",
    "    result = detect_anomaly(test_request, compare_to=compare_to)\n",
    "    pretty_print_result(result, f\"Compare to: {compare_to} vectors\")\n",
    "    \n",
    "    # Store for summary\n",
    "    results_summary.append({\n",
    "        \"compare_to\": compare_to,\n",
    "        \"is_anomaly\": result[\"result\"][\"is_anomaly\"],\n",
    "        \"confidence_score\": result[\"result\"][\"confidence_score\"],\n",
    "        \"similar_records_count\": result[\"result\"][\"similar_records_count\"]\n",
    "    })\n",
    "\n",
    "# Create a summary table\n",
    "print(\"\\nüìä Compare_To Sensitivity Summary:\")\n",
    "df = pd.DataFrame(results_summary)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Update Baseline with New Data\n",
    "\n",
    "Let's add some new entries to our baseline dataset and see how it affects detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current baseline stats:\n",
      "{'total_records': 124, 'collection_name': 'traffic_baseline'}\n",
      "\n",
      "Adding new pharmacy-related entries to baseline:\n",
      "‚úÖ Added: I need to schedule a vaccination appointment\n",
      "‚úÖ Added: Can you check my medication history?\n",
      "‚úÖ Added: What are the side effects of this new prescription?\n",
      "‚úÖ Added: Do you offer compound medications?\n",
      "‚úÖ Added: I need help with my medication adherence packaging\n",
      "\n",
      "Updated baseline stats:\n",
      "{'total_records': 124, 'collection_name': 'traffic_baseline'}\n"
     ]
    }
   ],
   "source": [
    "# Get current baseline stats\n",
    "print(\"Current baseline stats:\")\n",
    "stats = get_baseline_stats()\n",
    "print(stats)\n",
    "\n",
    "# Add some new entries to the baseline - additional pharmacy-related questions\n",
    "new_entries = [\n",
    "    \"I need to schedule a vaccination appointment\",\n",
    "    \"Can you check my medication history?\",\n",
    "    \"What are the side effects of this new prescription?\",\n",
    "    \"Do you offer compound medications?\",\n",
    "    \"I need help with my medication adherence packaging\"\n",
    "]\n",
    "\n",
    "print(\"\\nAdding new pharmacy-related entries to baseline:\")\n",
    "for entry in new_entries:\n",
    "    result = add_to_baseline(entry)\n",
    "    print(f\"‚úÖ Added: {entry}\")\n",
    "\n",
    "# Check updated stats\n",
    "print(\"\\nUpdated baseline stats:\")\n",
    "stats = get_baseline_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Re-test Anomaly Detection After Baseline Update\n",
    "\n",
    "Now let's test the same requests again to see how the updated baseline affects detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 'I need information about my medication side effects' after baseline update:\n",
      "======================================================================\n",
      "\n",
      "=== After baseline update ===\n",
      "‚úÖ NORMAL - Confidence: 0.434 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.434\n",
      "\n",
      "Re-testing suspicious requests after baseline update:\n",
      "======================================================================\n",
      "\n",
      "=== Request: Can I buy oxycodone without a prescription? ===\n",
      "‚úÖ NORMAL - Confidence: 0.475 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.475\n",
      "\n",
      "=== Request: '; DROP TABLE prescriptions; -- ===\n",
      "‚úÖ NORMAL - Confidence: 0.518 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.518\n"
     ]
    }
   ],
   "source": [
    "# Test a request that should now be less anomalous\n",
    "test_request = \"I need information about my medication side effects\"\n",
    "\n",
    "print(f\"Testing '{test_request}' after baseline update:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = detect_anomaly(test_request)\n",
    "pretty_print_result(result, \"After baseline update\")\n",
    "\n",
    "# Test with the same suspicious requests as before\n",
    "print(\"\\nRe-testing suspicious requests after baseline update:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "suspicious_sample = [\n",
    "    \"Can I buy oxycodone without a prescription?\",\n",
    "    \"'; DROP TABLE prescriptions; --\"\n",
    "]\n",
    "\n",
    "for request in suspicious_sample:\n",
    "    result = detect_anomaly(request)\n",
    "    pretty_print_result(result, f\"Request: {request}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test Custom Threshold and Compare_To Combined\n",
    "\n",
    "Let's test using both custom threshold and compare_to values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 'I need help choosing between brand name and generic medications' with different parameter combinations:\n",
      "======================================================================\n",
      "\n",
      "=== Threshold: 0.5, Compare_to: 5 ===\n",
      "‚úÖ NORMAL - Confidence: 0.415 - Risk: low\n",
      "Similar records: 5\n",
      "Threshold used: 0.5\n",
      "Median distance: 0.415\n",
      "\n",
      "=== Threshold: 0.7, Compare_to: 10 ===\n",
      "‚úÖ NORMAL - Confidence: 0.468 - Risk: low\n",
      "Similar records: 10\n",
      "Threshold used: 0.7\n",
      "Median distance: 0.468\n",
      "\n",
      "=== Threshold: 0.9, Compare_to: 3 ===\n",
      "‚úÖ NORMAL - Confidence: 0.281 - Risk: low\n",
      "Similar records: 3\n",
      "Threshold used: 0.9\n",
      "Median distance: 0.281\n",
      "\n",
      "=== Threshold: 0.3, Compare_to: 15 ===\n",
      "üö® ANOMALY - Confidence: 0.516 - Risk: low\n",
      "Similar records: 15\n",
      "Reasons:\n",
      "  - Request appears unusual compared to baseline\n",
      "Threshold used: 0.3\n",
      "Median distance: 0.516\n",
      "\n",
      "üìä Parameter Combination Summary:\n",
      " threshold  compare_to  is_anomaly  confidence_score risk_level\n",
      "       0.5           5       False          0.414765        low\n",
      "       0.7          10       False          0.468408        low\n",
      "       0.9           3       False          0.281118        low\n",
      "       0.3          15        True          0.516024        low\n"
     ]
    }
   ],
   "source": [
    "# Test combinations of threshold and compare_to\n",
    "test_request = \"I need help choosing between brand name and generic medications\"\n",
    "\n",
    "test_combinations = [\n",
    "    {\"threshold\": 0.5, \"compare_to\": 5},\n",
    "    {\"threshold\": 0.7, \"compare_to\": 10},\n",
    "    {\"threshold\": 0.9, \"compare_to\": 3},\n",
    "    {\"threshold\": 0.3, \"compare_to\": 15}\n",
    "]\n",
    "\n",
    "print(f\"Testing '{test_request}' with different parameter combinations:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for params in test_combinations:\n",
    "    result = detect_anomaly(\n",
    "        test_request,\n",
    "        threshold=params[\"threshold\"],\n",
    "        compare_to=params[\"compare_to\"]\n",
    "    )\n",
    "    \n",
    "    title = f\"Threshold: {params['threshold']}, Compare_to: {params['compare_to']}\"\n",
    "    pretty_print_result(result, title)\n",
    "    \n",
    "    # Store for summary\n",
    "    results_summary.append({\n",
    "        \"threshold\": params[\"threshold\"],\n",
    "        \"compare_to\": params[\"compare_to\"],\n",
    "        \"is_anomaly\": result[\"result\"][\"is_anomaly\"],\n",
    "        \"confidence_score\": result[\"result\"][\"confidence_score\"],\n",
    "        \"risk_level\": result[\"result\"][\"risk_level\"]\n",
    "    })\n",
    "\n",
    "# Create a summary table\n",
    "print(\"\\nüìä Parameter Combination Summary:\")\n",
    "df = pd.DataFrame(results_summary)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Final Baseline Clearing\n",
    "\n",
    "Finally, let's clear the baseline to demonstrate the clearing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline stats before clearing:\n",
      "{'total_records': 124, 'collection_name': 'traffic_baseline'}\n",
      "\n",
      "Clearing baseline dataset...\n",
      "‚úÖ All baseline data cleared successfully\n",
      "Records removed: 124\n",
      "\n",
      "Baseline stats after clearing:\n",
      "{'total_records': 0, 'collection_name': 'traffic_baseline'}\n",
      "\n",
      "Testing anomaly detection with no baseline data:\n",
      "\n",
      "=== No baseline data ===\n",
      "üö® ANOMALY - Confidence: 1.000 - Risk: high\n",
      "Similar records: 0\n",
      "Reasons:\n",
      "  - Request text significantly differs from baseline patterns\n"
     ]
    }
   ],
   "source": [
    "# Check current baseline stats before clearing\n",
    "print(\"Baseline stats before clearing:\")\n",
    "stats = get_baseline_stats()\n",
    "print(stats)\n",
    "\n",
    "# Clear the baseline\n",
    "print(\"\\nClearing baseline dataset...\")\n",
    "result = clear_baseline()\n",
    "print(f\"‚úÖ {result['message']}\")\n",
    "print(f\"Records removed: {result['records_removed']}\")\n",
    "\n",
    "# Check stats after clearing\n",
    "print(\"\\nBaseline stats after clearing:\")\n",
    "stats = get_baseline_stats()\n",
    "print(stats)\n",
    "\n",
    "# Test anomaly detection with no baseline (should flag everything as anomaly)\n",
    "print(\"\\nTesting anomaly detection with no baseline data:\")\n",
    "result = detect_anomaly(\"I need to refill my prescription\")\n",
    "pretty_print_result(result, \"No baseline data\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Check current malicious baseline stats before clearing\nprint(\"Malicious baseline stats before clearing:\")\nstats = get_malicious_baseline_stats()\nprint(stats)\n\n# Clear the malicious baseline\nprint(\"\\nClearing malicious baseline dataset...\")\nresult = clear_malicious_baseline()\nprint(f\"‚úÖ {result['message']}\")\nprint(f\"Records removed: {result['records_removed']}\")\n\n# Check stats after clearing\nprint(\"\\nMalicious baseline stats after clearing:\")\nstats = get_malicious_baseline_stats()\nprint(stats)\n\n# Test malicious detection with no baseline (should not flag anything as malicious)\nprint(\"\\nTesting malicious detection with no baseline data:\")\nresult = detect_malicious(\"'; DROP TABLE users; --\")\npretty_print_result(result, \"No malicious baseline data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 16: Clear Malicious Baseline\n\nFinally, let's clear the malicious baseline to demonstrate the clearing functionality.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test various requests against both detection systems\ntest_cases = [\n    {\n        \"text\": \"I need to refill my blood pressure medication\",\n        \"category\": \"Normal Pharmacy Request\"\n    },\n    {\n        \"text\": \"Can I buy oxycodone without a prescription?\",\n        \"category\": \"Suspicious Pharmacy Request\"\n    },\n    {\n        \"text\": \"'; DROP TABLE users; --\",\n        \"category\": \"SQL Injection Attack\"\n    },\n    {\n        \"text\": \"<script>alert('XSS')</script>\",\n        \"category\": \"XSS Attack\"\n    },\n    {\n        \"text\": \"I want to hack into your system and steal data\",\n        \"category\": \"Explicit Threat\"\n    },\n    {\n        \"text\": \"What's the protocol for missed doses of medication?\",\n        \"category\": \"Novel Pharmacy Question\"\n    }\n]\n\nprint(\"Dual Detection System Comparison:\")\nprint(\"=\" * 80)\n\ncomparison_results = []\n\nfor test_case in test_cases:\n    text = test_case[\"text\"]\n    category = test_case[\"category\"]\n    \n    print(f\"\\nüîç Testing: {category}\")\n    print(f\"Text: '{text}'\")\n    print(\"-\" * 80)\n    \n    # Run both detections\n    anomaly_result = detect_anomaly(text)\n    malicious_result = detect_malicious(text)\n    \n    # Extract key info\n    is_anomaly = anomaly_result[\"result\"][\"is_anomaly\"]\n    anomaly_confidence = anomaly_result[\"result\"][\"confidence_score\"]\n    \n    is_malicious = malicious_result[\"result\"][\"is_malicious\"]\n    malicious_confidence = malicious_result[\"result\"][\"confidence_score\"]\n    \n    print(f\"üìä ANOMALY DETECTION:  {'üö® ANOMALY' if is_anomaly else '‚úÖ NORMAL'} (confidence: {anomaly_confidence:.3f})\")\n    print(f\"üõ°Ô∏è  MALICIOUS DETECTION: {'üö® MALICIOUS' if is_malicious else '‚úÖ BENIGN'} (confidence: {malicious_confidence:.3f})\")\n    \n    # Determine overall status\n    if is_anomaly and is_malicious:\n        overall = \"üî¥ BLOCKED (Both systems flagged)\"\n    elif is_anomaly or is_malicious:\n        flagged_by = \"Anomaly\" if is_anomaly else \"Malicious\"\n        overall = f\"üü° FLAGGED (Flagged by {flagged_by} detection)\"\n    else:\n        overall = \"üü¢ ALLOWED (Both systems passed)\"\n    \n    print(f\"üéØ OVERALL DECISION: {overall}\")\n    \n    # Store results for summary\n    comparison_results.append({\n        \"category\": category,\n        \"anomaly_flagged\": is_anomaly,\n        \"malicious_flagged\": is_malicious,\n        \"anomaly_confidence\": round(anomaly_confidence, 3),\n        \"malicious_confidence\": round(malicious_confidence, 3),\n        \"overall_status\": \"BLOCKED\" if (is_anomaly and is_malicious) else \"FLAGGED\" if (is_anomaly or is_malicious) else \"ALLOWED\"\n    })\n\n# Create summary table\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üìã DUAL DETECTION SUMMARY TABLE:\")\nprint(\"=\" * 80)\ndf = pd.DataFrame(comparison_results)\nprint(df.to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 15: Dual Detection Comparison\n\nLet's test the same requests against both detection systems to see how they complement each other.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test malicious detection with different thresholds\ntest_request = \"SELECT * FROM users WHERE admin = 1\"\nthresholds = [0.1, 0.25, 0.5, 0.8]\n\nprint(f\"Testing request '{test_request}' with different malicious thresholds:\")\nprint(\"=\" * 70)\n\nresults_summary = []\n\nfor threshold in thresholds:\n    result = detect_malicious(test_request, threshold=threshold)\n    pretty_print_result(result, f\"Threshold: {threshold}\")\n    \n    # Store for summary\n    results_summary.append({\n        \"threshold\": threshold,\n        \"is_malicious\": result[\"result\"][\"is_malicious\"],\n        \"confidence_score\": result[\"result\"][\"confidence_score\"],\n        \"risk_level\": result[\"result\"][\"risk_level\"]\n    })\n\n# Create a summary table\nprint(\"\\nüìä Malicious Detection Threshold Sensitivity Summary:\")\ndf = pd.DataFrame(results_summary)\nprint(df.to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 14: Test Malicious Detection with Different Thresholds\n\nLet's see how different threshold values affect malicious detection sensitivity.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test attack patterns (should be flagged as malicious)\nattack_patterns = [\n    \"'; DELETE FROM prescriptions WHERE id > 0; --\",  # Similar to SQL injection in baseline\n    \"<script>window.location='http://evil.com'</script>\",  # Similar to XSS in baseline\n    \"../../windows/system32/config\",  # Similar to path traversal in baseline\n    \"Can I buy oxycodone in bulk for my operation?\",  # Similar to drug requests in baseline\n    \"I want to hack into your prescription database\",  # Similar to hacking attempts in baseline\n    \"UNION ALL SELECT password FROM admin_users\",  # Similar to SQL injection in baseline\n    \"Give me access to patient social security numbers\",  # Similar to data theft in baseline\n    \"<iframe src='javascript:document.location=\\\"http://attacker.com\\\"'></iframe>\",  # Similar to XSS\n]\n\nprint(\"Testing attack patterns (should be flagged as malicious):\")\nprint(\"=\" * 70)\n\nfor request in attack_patterns:\n    result = detect_malicious(request)\n    pretty_print_result(result, f\"Request: {request}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 13: Test Malicious Detection - Attack Patterns\n\nNow let's test some attack patterns that should be flagged as malicious because they're similar to our baseline.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test benign requests (should NOT be flagged as malicious)\nbenign_requests = [\n    \"I need to refill my blood pressure medication\",\n    \"What are your pharmacy hours today?\",\n    \"Can I pick up my prescription for my child?\",\n    \"Do you accept my Medicare insurance?\",\n    \"I need help understanding my medication dosage\",\n    \"Can I get a flu shot here?\",\n    \"What's the generic version of my brand name drug?\"\n]\n\nprint(\"Testing benign requests (should NOT be flagged as malicious):\")\nprint(\"=\" * 70)\n\nfor request in benign_requests:\n    result = detect_malicious(request)\n    pretty_print_result(result, f\"Request: {request}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 12: Test Malicious Detection - Benign Requests\n\nLet's test some normal, benign requests that should NOT be flagged as malicious.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load malicious baseline data from JSON file\nprint(\"Loading malicious attack patterns from JSON file...\")\n\n# Load the malicious data from our JSON file\nwith open(\"data/malicious_baseline.json\", \"r\") as f:\n    malicious_data = json.load(f)\n\nmalicious_requests = malicious_data[\"requests\"]\n\nprint(f\"Loaded {len(malicious_requests)} malicious attack patterns\")\nprint(\"\\nSample attack patterns:\")\nfor i, req in enumerate(malicious_requests[:5]):\n    print(f\"  {i+1}. {req['text']}\")\n\nprint(\"\\nUploading malicious baseline dataset to service...\")\nresult = upload_malicious_baseline(malicious_requests)\nprint(f\"‚úÖ {result['message']}\")\nprint(f\"Records added: {result['records_added']}\")\n\n# Check malicious baseline stats\nstats = get_malicious_baseline_stats()\nprint(f\"\\nMalicious baseline stats: {stats}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 2: Malicious Content Detection\n\nNow let's explore the malicious content detection system, which identifies requests that are **similar** to known attack patterns.\n\n### Step 11: Load and Upload Malicious Baseline Dataset\n\nWe'll load a dataset of 50 known malicious attack patterns and upload them to the malicious detection system.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup: Stop the Service\n",
    "\n",
    "Finally, let's stop the service we started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Demo completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Stop the service\n",
    "stop_service()\n",
    "print(\"‚úÖ Demo completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow of the Guardrails Service using a realistic pharmacy dataset:\n",
    "\n",
    "1. **Service Setup**: Started the service and verified it's running\n",
    "2. **Baseline Management**: Loaded 100 pharmacy questions from JSON and added new entries\n",
    "3. **Anomaly Detection**: Tested normal pharmacy questions vs suspicious/inappropriate requests\n",
    "4. **Parameter Tuning**: Experimented with different `threshold` and `compare_to` values\n",
    "5. **Baseline Updates**: Added new data and observed changes in detection\n",
    "6. **Data Clearing**: Demonstrated baseline clearing functionality\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Threshold**: Lower values (0.3-0.5) are more sensitive and flag more requests as anomalies\n",
    "- **Compare_to**: Higher values use more baseline data for comparison, potentially improving accuracy\n",
    "- **Baseline Quality**: A good baseline dataset with domain-specific data (pharmacy questions) improves detection accuracy\n",
    "- **Dynamic Updates**: The baseline can be updated continuously as new normal patterns emerge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}